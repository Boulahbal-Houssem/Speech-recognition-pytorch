{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"name":"prepareData.ipynb","version":"0.3.2","provenance":[],"collapsed_sections":[]},"kernelspec":{"name":"python3","display_name":"Python 3"}},"cells":[{"metadata":{"id":"Ls31FUe7sQNX","colab_type":"code","outputId":"b1048506-aa11-4f2f-c01e-1dcd706f51c7","executionInfo":{"status":"ok","timestamp":1555790331682,"user_tz":-120,"elapsed":29644,"user":{"displayName":"Houssem eddine","photoUrl":"","userId":"14952848185624325350"}},"colab":{"base_uri":"https://localhost:8080/","height":124}},"cell_type":"code","source":["from google.colab import drive\n","drive.mount('/mydrive')"],"execution_count":1,"outputs":[{"output_type":"stream","text":["Go to this URL in a browser: https://accounts.google.com/o/oauth2/auth?client_id=947318989803-6bn6qk8qdgf4n4g3pfee6491hc0brc4i.apps.googleusercontent.com&redirect_uri=urn%3Aietf%3Awg%3Aoauth%3A2.0%3Aoob&scope=email%20https%3A%2F%2Fwww.googleapis.com%2Fauth%2Fdocs.test%20https%3A%2F%2Fwww.googleapis.com%2Fauth%2Fdrive%20https%3A%2F%2Fwww.googleapis.com%2Fauth%2Fdrive.photos.readonly%20https%3A%2F%2Fwww.googleapis.com%2Fauth%2Fpeopleapi.readonly&response_type=code\n","\n","Enter your authorization code:\n","··········\n","Mounted at /mydrive\n"],"name":"stdout"}]},{"metadata":{"id":"pqH3HKuGsgzd","colab_type":"code","outputId":"6dbc7527-fe1a-4a58-bc26-f62e29e0acfb","executionInfo":{"status":"ok","timestamp":1555790368055,"user_tz":-120,"elapsed":488,"user":{"displayName":"Houssem eddine","photoUrl":"","userId":"14952848185624325350"}},"colab":{"base_uri":"https://localhost:8080/","height":52}},"cell_type":"code","source":["cd /mydrive/My Drive/Colab Notebooks/Speech-Commands-Recognition"],"execution_count":7,"outputs":[{"output_type":"stream","text":["[Errno 2] No such file or directory: './mydrive/My Drive/Colab Notebooks/Speech-Commands-Recognition'\n","/\n"],"name":"stdout"}]},{"metadata":{"id":"bkrSZuMfsn9f","colab_type":"code","colab":{}},"cell_type":"code","source":["import librosa\n","from utils import util\n","import matplotlib.pyplot as plt\n","import numpy as np\n","import cv2\n","import os\n","from tqdm import tqdm\n","from scipy import signal\n","import torch\n","from torchvision import datasets, transforms, models"],"execution_count":0,"outputs":[]},{"metadata":{"id":"YQEIVOxCEAXx","colab_type":"code","colab":{}},"cell_type":"code","source":["def augentationMethod(data,dest_dir,curr_file,disr):\n","  sr = 16000\n","  ran = np.random.normal(0,2)\n","  if (ran >-0.8 and ran <0.8):\n","    return False\n","  elif (ran <=-0.8 ):# Time shifting method\n","      start_ = int(np.random.uniform(-4800,4800))\n","      if start_ >= 0:\n","        data = np.r_[data[start_:], np.random.uniform(-0.001,0.001, start_)]\n","      else:\n","        data = np.r_[np.random.uniform(-0.001,0.001, -start_), data[:start_]] \n","        \n","  elif (ran >= 0.8 ):# Speed tuning\n","    speed_rate = np.random.uniform(0.7,1.3)\n","    wav_speed_tune = cv2.resize(data, (1, int(len(data) * speed_rate))).squeeze()\n","    if len(wav_speed_tune) < 16000:\n","      pad_len = 16000 - len(wav_speed_tune)\n","      data = np.r_[np.random.uniform(-0.001,0.001,int(pad_len/2)),\n","                           wav_speed_tune,\n","                           np.random.uniform(-0.001,0.001,int(np.ceil(pad_len/2)))]\n","    else: \n","      cut_len = len(wav_speed_tune) - 16000\n","      data = wav_speed_tune[int(cut_len/2):int(cut_len/2)+16000]\n","  freq, times, spec = util.log_spectogram(data, sr)\n","  fig, ax = plt.subplots(1)\n","  fig.subplots_adjust(left=0, right=1, bottom=0, top=1)\n","  ax.axis('off')\n","  ax.imshow(spec.T, aspect='auto', origin='lower')\n","  ax.axis('off')\n","  fig.savefig(f'{dest_dir}/{disr}/{curr_file[:-4]}'+str(ran)+'.jpg')\n","  plt.close(fig)"],"execution_count":0,"outputs":[]},{"metadata":{"id":"U074Xl1y9kwH","colab_type":"code","colab":{}},"cell_type":"code","source":["import traceback"],"execution_count":0,"outputs":[]},{"metadata":{"id":"ikXAgLIZyp_J","colab_type":"code","colab":{}},"cell_type":"code","source":["def augment_audio(src_dir, dest_dir):\n","    \"\"\"\n","    Generate spectograms from audio files.\n","\n","    Parameters:\n","        src_dir - directory containing folders of different classes \n","                  which contain their respective audio files\n","        dest_dir - directory to store spectograms\n","                   (directory should contain empty folders of respective classes)\n","\n","    \"\"\"\n","    # src_dir = '../datasets/data_audio/train/'\n","    # dest_dir = '../datasets/data_images/train/'\n","    dirs = ['yes','on','no','off', 'up', 'down', 'left',\n","            'right', 'go', 'stop'] \n","    for dir in dirs:\n","        \n","          print(dir)\n","          audio_files = os.listdir(f'{src_dir}{dir}')\n","          j=0\n","          for curr_file in audio_files:\n","            try:\n","              j +=1\n","              data, sr = librosa.load(f'{src_dir}{dir}/{curr_file}', sr=16000)\n","              freq, times, spec = util.log_spectogram(data, sr)\n","              fig, ax = plt.subplots(1)\n","              fig.subplots_adjust(left=0, right=1, bottom=0, top=1)\n","              ax.axis('off')\n","              ax.imshow(spec.T, aspect='auto', origin='lower')\n","              ax.axis('off')\n","              fig.savefig(f'{dest_dir}/{dir}/{curr_file[:-4]}.jpg')\n","              plt.close(fig)\n","              augentationMethod(data,dest_dir,curr_file,dir)\n","              if(j  == 1000):\n","                print('done 1000' + str(j) ,end='\\r')\n","            except Exception:\n","              print('error')  \n","          print(j)"],"execution_count":0,"outputs":[]},{"metadata":{"id":"gj9Jd3vL6ad4","colab_type":"code","outputId":"3b526f57-dccb-47bb-bedf-a31da4f6ba22","executionInfo":{"status":"error","timestamp":1550445412504,"user_tz":-60,"elapsed":756,"user":{"displayName":"amir Beddiaf","photoUrl":"","userId":"00319192126174256345"}},"colab":{"base_uri":"https://localhost:8080/","height":34}},"cell_type":"code","source":["augment_audio(\"./PrepareData/dataset/\",\"./PrepareData/dataset/train\")"],"execution_count":0,"outputs":[{"output_type":"stream","text":["off\n"],"name":"stdout"}]}]}